{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import featuretools as ft\n",
    "import mrmr\n",
    "from mrmr import mrmr_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from woodwork.logical_types import Boolean, AgeNullable, Ordinal, Categorical, AgeFractional, Integer, Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dataframes \n",
    "df_train = pd.read_csv('../cleaned_imputed_split/X_train.csv')\n",
    "df_val = pd.read_csv('../cleaned_imputed_split/X_val.csv')\n",
    "df_test = pd.read_csv('../cleaned_imputed_split/X_test.csv')\n",
    "\n",
    "df_HQ_train = pd.read_csv('../Processed datasets/After outlier analysis/HQ.csv')\n",
    "df_FFQ_train = pd.read_csv('../Processed datasets/After outlier analysis/FFQ.csv')\n",
    "df_CM_train = pd.read_csv('../Processed datasets/After outlier analysis/CM.csv')\n",
    "df_CE_train = pd.read_csv('../Processed datasets/After outlier analysis/CE.csv')\n",
    "\n",
    "y_train = pd.read_csv('../cleaned_imputed_split/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list that contains the train dataframe, validation dataframe and test dataframe \n",
    "list_of_dataframes = [df_train, df_val, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_columns_FFQ = df_FFQ_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-point ordinal scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the FFQ questions with 9 answer categories, and set dtype to ordinal\n",
    "dtypes_FFQ = {}\n",
    "\n",
    "for column in df_FFQ_train:\n",
    "    if len(df_FFQ_train[column].unique()) == 9:\n",
    "        dtypes_FFQ[column] = Ordinal(order=[1,2,3,4,5,6,7,8,9])\n",
    "        complete_columns_FFQ.remove(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-point ordinal scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 4 answer categories \n",
    "for column in df_FFQ_train:\n",
    "    if len(df_FFQ_train[column].unique()) == 4:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ordinal ones and assign correct dtype\n",
    "for column in ['JMEATFAT', 'JFRYEAT']:\n",
    "    dtypes_FFQ[column] = Ordinal(order=[1,2,3,4])\n",
    "    complete_columns_FFQ.remove(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-points ordinal scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 5 answer categories \n",
    "for column in df_FFQ_train:\n",
    "    if len(df_FFQ_train[column].unique()) == 5:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ordinal ones and assign correct dtype\n",
    "for column in ['JSALTTAB', 'JSALTCK']:\n",
    "    dtypes_FFQ[column] = Ordinal(order=[1,2,3,4,5])\n",
    "    complete_columns_FFQ.remove(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-points ordinal scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 6 answer categories \n",
    "for column in df_FFQ_train:\n",
    "    if len(df_FFQ_train[column].unique()) == 6:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ordinal ones and assign correct dtype\n",
    "dtypes_FFQ['JMILKDAY'] = Ordinal(order=[1,2,3,4,5,6])\n",
    "complete_columns_FFQ.remove('JMILKDAY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-point categorical scales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical ones and assign correct dtype\n",
    "for column in ['JFRYFAT', 'JBAKEFAT']:\n",
    "        dtypes_FFQ[column] = Categorical\n",
    "        complete_columns_FFQ.remove(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-point categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 7 answer categories \n",
    "for column in df_FFQ_train:\n",
    "    if len(df_FFQ_train[column].unique()) == 7:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical ones and assign correct dtype \n",
    "dtypes_FFQ['JMILKUSE'] = Categorical\n",
    "complete_columns_FFQ.remove('JMILKUSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ordinal ones and assign correct dtype \n",
    "dtypes_FFQ['JDIETLNG'] = Ordinal(order=[0,1,2,3,4,5,6])\n",
    "complete_columns_FFQ.remove('JDIETLNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Booleans and assign correct dtype\n",
    "for column in df_FFQ_train:\n",
    "    if len(df_FFQ_train[column].unique())<=2:\n",
    "        dtypes_FFQ[column] = Boolean\n",
    "        complete_columns_FFQ.remove(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining questions are all the 9-point food frequency questions\n",
    "for column in complete_columns_FFQ:\n",
    "    dtypes_FFQ[column] = Ordinal(order=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_Q = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify boolean variables and assign correct dtype\n",
    "booleans = []\n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique())<=2:\n",
    "        booleans.append(column)\n",
    "        dtypes_Q[column] = Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dtype of one of the features created in this study to Boolean as well\n",
    "dtypes_Q['problematic_drinking'] = Boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-point scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 3 answer categories \n",
    "total3 = []\n",
    "\n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 3:\n",
    "        total3.append(column)\n",
    "\n",
    "total3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "for column in total3:\n",
    "    if column.startswith('JACTI'):\n",
    "        dtypes_Q[column] = Ordinal(order=[1,2,3])\n",
    "    elif column == 'JGHQ30':\n",
    "        dtypes_Q[column] = Ordinal(order=[1,2,3,4])\n",
    "    else:\n",
    "         dtypes_Q[column] = Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-point scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 4 answer categories \n",
    "total4 = []\n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 4:\n",
    "        total4.append(column)\n",
    "total4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns that are categorical\n",
    "categorical4 = ['JSTATUSX','JCHPACT','JSLDRIVE','JSNORBOT','JACCOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 4:\n",
    "        if column.startswith('JDPN'):\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3])\n",
    "        elif column == 'JCAR':\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3])\n",
    "        elif column == 'JTRLEP':\n",
    "            dtypes_Q[column] = Integer\n",
    "        elif column in categorical4:\n",
    "            dtypes_Q[column] = Categorical\n",
    "        else:\n",
    "            dtypes_Q[column] = Ordinal(order=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-point scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 5 answer categories \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 5:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categoricals, and ordinals that actually have more than 5 options\n",
    "categorical5 = 'JNOTMAR'\n",
    "ordinal7 = ['JCARWASF', 'JSOCCERF', 'JSOCCERH', 'JGOLFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 5:\n",
    "        if column in categorical5:\n",
    "            dtypes_Q[column] = Categorical\n",
    "        elif column == 'JPETATTA':\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3,4])\n",
    "        elif column in ordinal7:\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3,4,5,6])\n",
    "        else:\n",
    "            dtypes_Q[column] = Ordinal(order=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-point scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 6 answer categories \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 6:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all categorical features \n",
    "categorical6 =['JBREAD', 'JMILKTYP', 'JLRNE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 6:\n",
    "        if column in categorical6:\n",
    "            dtypes_Q[column] = Categorical\n",
    "        elif column == 'JCHPNUM' or column == 'JGOUT_YR':\n",
    "            dtypes_Q[column] = Integer\n",
    "        elif column == 'JGOLFH' or column == 'JMOWF':\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3,4,5,6])\n",
    "        elif column == 'JSNORHOW':\n",
    "            dtypes_Q[column] = Ordinal(order=[0,5,1,2,3,4])\n",
    "        elif column == 'JLRNE':\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3,4,5])\n",
    "        else:\n",
    "            dtypes_Q[column] = Ordinal(order=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-point scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 7 answer categories \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 7:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 7:\n",
    "        if column.startswith('JAR'):\n",
    "            dtypes_Q[column] = Ordinal(order=[1,2,3,4,5,6,7])\n",
    "        elif column == 'JSNOROFT':\n",
    "            dtypes_Q[column] = Ordinal(order=[1,2,3,4,5,6,0])\n",
    "        elif column == 'JOST_PYR' or column == 'JFRUITVG' or column == 'JRHE_AYR':\n",
    "            dtypes_Q[column] = Integer\n",
    "        else:\n",
    "            dtypes_Q[column] = Ordinal(order=[0,1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-point scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 8 answer categories \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 8:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 8:\n",
    "        if column == 'JASSETHH':\n",
    "            dtypes_Q[column] = Ordinal(order=[1,2,3,4,5,6,7,8])\n",
    "        else:\n",
    "            dtypes_Q[column] = Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-point scales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all questions with 9 answer categories \n",
    "for column in df_HQ_train:\n",
    "    if len(df_HQ_train[column].unique()) == 9:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtypes \n",
    "dtypes_Q['JHSADMNO'] = Integer \n",
    "dtypes_Q['JVIGFQ_S'] = Integer \n",
    "dtypes_Q['JTSF'] = Integer\n",
    "dtypes_Q['JINCHH'] = Ordinal(order=[1,2,3,4,5,6,7,8,9])\n",
    "dtypes_Q['JASSETXH'] = Ordinal(order=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left over features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which features did not got assigned a dtype yet \n",
    "columns_in_dataframe = df_HQ_train.columns.to_list()\n",
    "keys = dtypes_Q.keys()\n",
    "key_list = list(keys)\n",
    "difference = list(set(columns_in_dataframe) - set(key_list))\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for non-integer features \n",
    "dtypes_Q['JCASPAUT'] = Ordinal(order=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "dtypes_Q['JLRCLGD'] = Categorical\n",
    "dtypes_Q['JAGE_C'] = AgeFractional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign integer dtype to all other features \n",
    "for column in difference:\n",
    "    dtypes_Q[column] = Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update existing dtype dictionary with new dtypes \n",
    "dtypes_FFQ.update(dtypes_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_CM = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns_CM = df_CM_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the datatype of all features that start with JMG to categorical \n",
    "CM_categorical = []\n",
    "for column in df_CM_train:\n",
    "    if column.startswith('JMG'):\n",
    "        dtypes_CM[column] = Categorical\n",
    "        CM_categorical.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which features are not categorical \n",
    "columns_CM = [x for x in total_columns_CM if x not in CM_categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all booleans\n",
    "booleans = []\n",
    "for column in columns_CM:\n",
    "    if len(df_CM_train[column].unique())<=2:\n",
    "        booleans.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtype\n",
    "for column in booleans:\n",
    "    dtypes_CM[column] = Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which features are left \n",
    "columns_CM = [x for x in columns_CM if x not in booleans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct dtype based on int or float\n",
    "for column in columns_CM:\n",
    "    if df_CM_train[column].dtype == 'int64':\n",
    "        dtypes_CM[column] = Integer\n",
    "    elif df_CM_train[column].dtype == 'float64':\n",
    "        dtypes_CM[column] = Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update datatype dictionary\n",
    "dtypes_FFQ.update(dtypes_CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_CE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All CM features are Booleans \n",
    "for column in df_CE_train:\n",
    "    dtypes_CE[column] = Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update datatype dictionary\n",
    "dtypes_FFQ.update(dtypes_CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary to access later \n",
    "with open('../cleaned_imputed_split/datatype_dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(dtypes_FFQ, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from float64 to float32 to save memory \n",
    "df_float64 = df_train.select_dtypes(include=['float64'])\n",
    "df_train[df_float64.columns] = df_float64.astype('float32')\n",
    "\n",
    "df_float64_val = df_val.select_dtypes(include=['float64'])\n",
    "df_val[df_float64_val.columns] = df_float64_val.astype('float32')\n",
    "\n",
    "df_float64_test = df_test.select_dtypes(include=['float64'])\n",
    "df_test[df_float64_test.columns] = df_float64_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy's of dataframes for late use \n",
    "df_train_copy = df_train.copy()\n",
    "df_val_copy = df_val.copy()\n",
    "df_test_copy = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Entity Set \n",
    "es = ft.EntitySet('T2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the dataframe and the correct dtypes \n",
    "es = es.add_dataframe(\n",
    "    dataframe_name = 'Q_FFQ', \n",
    "    dataframe = df_train,\n",
    "    index = 'Id_random_DPUK', \n",
    "    logical_types=dtypes_FFQ, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_val = ft.EntitySet('T2D_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_val = es_val.add_dataframe(\n",
    "    dataframe_name = 'Q_FFQ_val', \n",
    "    dataframe = df_val,\n",
    "    index = 'Id_random_DPUK', \n",
    "    logical_types=dtypes_FFQ, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_test = ft.EntitySet('T2D_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_test = es_test.add_dataframe(\n",
    "    dataframe_name = 'Q_FFQ_test', \n",
    "    dataframe = df_test,\n",
    "    index = 'Id_random_DPUK', \n",
    "    logical_types=dtypes_FFQ, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all datatypes are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['Q_FFQ'].ww.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of transform primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all possible transform primitives\n",
    "primitives = ft.list_primitives()\n",
    "trans_primitives = primitives.loc[primitives['type'] == 'transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate per category (Boolean, Integer,Double, Ordinal) which transformations are possible\n",
    "keywords = [ 'Boolean']\n",
    "trans_primitives_filtered = trans_primitives[trans_primitives['valid_inputs'].str.contains('|'.join(keywords))]\n",
    "trans_primitives_filtered = trans_primitives_filtered.drop(columns=['type', 'valid_inputs', 'return_type'])\n",
    "pd.options.display.max_colwidth = 300\n",
    "trans_primitives_filtered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically engineer features\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_dataframe_name='Q_FFQ', max_depth=1,\n",
    "                                      trans_primitives=['multiply_boolean','and', 'or', 'not',\n",
    "                                                        'square_root', 'multiply_numeric_boolean', \n",
    "                                                        'percentile', 'add_numeric', 'multiply_numeric',\n",
    "                                                        'subtract_numeric'])\n",
    "\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_val, feature_defs = ft.dfs(entityset=es_val, target_dataframe_name='Q_FFQ_val', max_depth=1,\n",
    "                                      trans_primitives=['multiply_boolean','and', 'or', 'not',\n",
    "                                                        'square_root', 'multiply_numeric_boolean', \n",
    "                                                        'percentile', 'add_numeric', 'multiply_numeric',\n",
    "                                                        'subtract_numeric'])\n",
    "\n",
    "feature_matrix_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test, feature_defs = ft.dfs(entityset=es_test, target_dataframe_name='Q_FFQ_test', max_depth=1,\n",
    "                                      trans_primitives=['multiply_boolean','and', 'or', 'not',\n",
    "                                                        'square_root', 'multiply_numeric_boolean', \n",
    "                                                        'percentile', 'add_numeric', 'multiply_numeric',\n",
    "                                                        'subtract_numeric'])\n",
    "\n",
    "feature_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indices \n",
    "feature_matrix.reset_index(drop=True, inplace=True)\n",
    "feature_matrix_val.reset_index(drop=True, inplace=True)\n",
    "feature_matrix_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change True and False back to 0 and 1 \n",
    "\n",
    "for column in feature_matrix.columns:\n",
    "    if feature_matrix[column].dtype == 'bool' or feature_matrix[column].dtype == 'boolean':\n",
    "        feature_matrix[column] = feature_matrix[column].astype(int)\n",
    "\n",
    "for column in feature_matrix_val.columns:\n",
    "    if feature_matrix_val[column].dtype == 'bool' or feature_matrix_val[column].dtype == 'boolean':\n",
    "        feature_matrix_val[column] = feature_matrix_val[column].astype(int)\n",
    "\n",
    "for column in feature_matrix_test.columns:\n",
    "    if feature_matrix_test[column].dtype == 'bool' or feature_matrix_test[column].dtype == 'boolean':\n",
    "        feature_matrix_test[column] = feature_matrix_test[column].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = len(feature_matrix.columns)\n",
    "step_size = 0.1 \n",
    "full_dataframe_mrmr = []\n",
    "\n",
    "num_steps = int(1/step_size)\n",
    "\n",
    "for i in range(num_steps):\n",
    "    start = int(i * step_size * num_columns)\n",
    "    end = int((i + 1) * step_size * num_columns)\n",
    "\n",
    "    column_list = list(feature_matrix.columns[start:end])\n",
    "    feature_matrix_slice = feature_matrix[column_list]\n",
    "    selected_features = mrmr_classif(X=feature_matrix_slice, y=y_train, K=150)\n",
    "    full_dataframe_mrmr.append(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Save 150 selected predictors per 10% of the data frame \n",
    "with open('../cleaned_imputed_split/150predictorsmrmr.pkl', 'wb') as f:\n",
    "    pickle.dump(full_dataframe_mrmr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the selected columns to a list \n",
    "concatenated_columns = [column for sublist in full_dataframe_mrmr for column in sublist]\n",
    "print(len(concatenated_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature matrix with only the selected 1500 columns\n",
    "feature_matrix_1500 = feature_matrix[concatenated_columns]\n",
    "\n",
    "# Save the created data frame \n",
    "feature_matrix_1500.to_csv('../cleaned_imputed_split/1500top_predictors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 500 predictors \n",
    "selected_features_500 = mrmr_classif(X=feature_matrix_1500, y=y_train, K=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save list of 500 features \n",
    "with open('../cleaned_imputed_split/500predictorsmrmr.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features_500, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframes to found 500 features\n",
    "mrmr_df_four_categories = feature_matrix[selected_features_500]\n",
    "mrmr_df_val_four_categories = feature_matrix_val[selected_features_500]\n",
    "mrmr_df_test_four_categories = feature_matrix_test[selected_features_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "mrmr_df_four_categories.to_csv('../Processed datasets/After splitting/mrmr/500selected_four_categories.csv', index=False)\n",
    "mrmr_df_val_four_categories.to_csv('../Processed datasets/After splitting/mrmr/500selected_val_four_categories.csv', index=False)\n",
    "mrmr_df_test_four_categories.to_csv('../Processed datasets/After splitting/mrmr/500selected_test_four_categories.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
